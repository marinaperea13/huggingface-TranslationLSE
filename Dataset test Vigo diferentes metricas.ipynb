{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "alert-repeat",
   "metadata": {},
   "source": [
    "## Loading dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "convinced-seeker",
   "metadata": {},
   "source": [
    "We get the metric we need to use for evaluation, in this case, SACREBLEU, ROUGE and METEOR, and we load the dataset using datasets library. In this case we define the test set as the set of Vigo sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "experienced-prophet",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /home/marina/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/marina/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/marina/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, load_metric\n",
    "bleu_metric = load_metric(\"sacrebleu\")\n",
    "rouge_metric = load_metric(\"rouge\")\n",
    "meteor_metric = load_metric(\"meteor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "regular-insert",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-8889dd37a417b922\n",
      "Reusing dataset json (/home/marina/.cache/huggingface/datasets/json/default-8889dd37a417b922/0.0.0/d75ead8d5cfcbe67495df0f89bd262f0023257fbbbd94a730313295f3d756d50)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b10ba215c79d4424814a5b5f2830b4ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset = load_dataset('json', data_files={'train': 'PHOENIX/dataset_train.json','test': 'PHOENIX/dataset_VIGO_test.json'}, field=\"data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cellular-brother",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accessible-guitar",
   "metadata": {},
   "source": [
    "With the following function we show some random examples of the dataset to see how data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "horizontal-prophet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'le': 'mañana por la noche tendremos aire más frío del oeste y cada vez se espera más nieve', 'ls': 'MAÑANA NOCHE LLEGA FRÍO REVISIÓN NIEVE VUELVE'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'le': 'las profundidades que se extienden desde los alpes hasta polonia traen lluvias a veces fuertes y tormentosas en el sur', 'ls': 'LOS ALPES LLEGAN BAJOS POLONIA LLEGAN LAS TORMENTAS DE LLUVIA'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'le': 'mañana luego mejora lenta en la zona costera todavía nubes bastante espesas dirección del viento tormentoso noreste amigable y seco', 'ls': 'MAÑANA LENTAMENTE MEJOR COSTA ACTUALMENTE NUBLADA TORMENTA NORESTE AMIGABLE IX'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'le': 'allí mañana hasta treinta y seis grados junto al mar, no tan inquietantemente caliente de veintisiete a veintinueve grados', 'ls': 'MAÑANA SUR HASTA SEIS TREINTA GRADOS NORTE GAY NEG-TIENE SIETE VEINTE A NUEVE GRADOS'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'le': 'el miércoles sigue lloviendo, especialmente en el medio y también en el sur', 'ls': 'MIERCOLES LLUVIA MAYORMENTE EN MEDIO DE LA REGION DE SUED'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>translation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'le': 'Soy intolerante a la lactosa.', 'ls': 'YO LECHE L+A+C+T+O+S+A INTOLERANCIA'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'le': '¿Tú qué crees?', 'ls': 'TÚ PENSAR CUÁL'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'le': 'Voy a revisión cada tres meses.', 'ls': 'REVISAR MES(TRES) MES(TRES)'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'le': 'La terapia del cáncer me afecta.', 'ls': 'CÁNCER TERAPIA AFECTAR(s)'}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'le': 'No tengo apetito y me dan mareos.', 'ls': 'YO COMER NO-ME-APETECE MAREOS'}</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import datasets\n",
    "import random\n",
    "import pandas as pd\n",
    "from IPython.display import display, HTML\n",
    "def show_random_elements(dataset, num_examples=5):\n",
    "    assert num_examples <= len(dataset), \"Can't pick more elements than there are in the dataset.\"\n",
    "    picks = []\n",
    "    for _ in range(num_examples):\n",
    "        pick = random.randint(0, len(dataset)-1)\n",
    "        while pick in picks:\n",
    "            pick = random.randint(0, len(dataset)-1)\n",
    "        picks.append(pick)\n",
    "    \n",
    "    df = pd.DataFrame(dataset[picks])\n",
    "    for column, typ in dataset.features.items():\n",
    "        if isinstance(typ, datasets.ClassLabel):\n",
    "            df[column] = df[column].transform(lambda i: typ.names[i])\n",
    "    display(HTML(df.to_html()))\n",
    "show_random_elements(dataset[\"train\"])\n",
    "show_random_elements(dataset[\"test\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "marine-workstation",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metallic-ensemble",
   "metadata": {},
   "source": [
    "## Preprocessing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "advised-warehouse",
   "metadata": {},
   "source": [
    "We load the pre-trained tokenizer that will tokenize the inputs and put them in a format that the model expects, and generate the other inputs that the model needs. By instantiating the tokenizer with from_pretrained function we ensure:\n",
    "- We get a tokenizer that corresponds to the architecture of the model we want to train\n",
    "- We download the vocabulary used when pretraining this specific checkpoint.\n",
    "\n",
    "We load the tokenizer of the previously pre-trained model on our PHOENIX dataset translated into Spanish."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "prostate-imaging",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"experimentos/full_dataset/checkpoint-14000\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fundamental-significance",
   "metadata": {},
   "source": [
    "Before feed the data to our model, we write the function that will preprocess our samples. With the argument `truncation=True` we ensure that an input longer than what the model selected can handle will be truncated to the maximum length accepted by the model. The padding will be dealt with later on (in a data collator) so we pad examples to the longest length in the batch and not the whole dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "stock-wages",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_input_length = 128\n",
    "max_target_length = 128\n",
    "source_lang = \"ls\"\n",
    "target_lang = \"le\"\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    inputs = [ex[source_lang] for ex in examples[\"translation\"]]\n",
    "    targets = [ex[target_lang] for ex in examples[\"translation\"]]\n",
    "    model_inputs = tokenizer(inputs, max_length=max_input_length, truncation=True)\n",
    "\n",
    "    # Setup the tokenizer for targets\n",
    "    with tokenizer.as_target_tokenizer():\n",
    "        labels = tokenizer(targets, max_length=max_target_length, truncation=True)\n",
    "\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "controlling-impossible",
   "metadata": {},
   "source": [
    "We use the map method of our dataset object created earlier to apply this function on all pairs of our dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "pointed-shield",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/marina/.cache/huggingface/datasets/json/default-8889dd37a417b922/0.0.0/d75ead8d5cfcbe67495df0f89bd262f0023257fbbbd94a730313295f3d756d50/cache-10b1cefa763b2fe4.arrow\n",
      "Loading cached processed dataset at /home/marina/.cache/huggingface/datasets/json/default-8889dd37a417b922/0.0.0/d75ead8d5cfcbe67495df0f89bd262f0023257fbbbd94a730313295f3d756d50/cache-25ec2bc5a9328840.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['attention_mask', 'input_ids', 'labels', 'translation'],\n",
       "        num_rows: 7096\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['attention_mask', 'input_ids', 'labels', 'translation'],\n",
       "        num_rows: 150\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset = dataset.map(preprocess_function, batched=True)\n",
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "realistic-punch",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "satisfactory-courage",
   "metadata": {},
   "source": [
    "## Fine-tuning the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifteen-irish",
   "metadata": {},
   "source": [
    "We download the pretrained model, for this we use the AutoModelForSeq2SeqLM since our task is of the sequence-to-sequence kind."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "competitive-samoa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSeq2SeqLM\n",
    "\n",
    "modelo = AutoModelForSeq2SeqLM.from_pretrained(\"experimentos/full_dataset/checkpoint-14000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "motivated-disclosure",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Seq2SeqTrainingArguments\n",
    "\n",
    "training_args = Seq2SeqTrainingArguments(\"experimentos/vigo_preentrenado\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    fp16=True,\n",
    "    eval_accumulation_steps=1,\n",
    "    predict_with_generate=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "atlantic-mortality",
   "metadata": {},
   "source": [
    "Seq2SeqTrainingArguments class contains the attributes to customize the training. It requires one folder name which will be used to save the checkpoints of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "violent-holocaust",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForSeq2Seq\n",
    "\n",
    "data_collator = DataCollatorForSeq2Seq(tokenizer, model=modelo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "embedded-senior",
   "metadata": {},
   "source": [
    "We define a function for compute the metrics from the predictions. This function use the metric we loaded earlier and decode the predictions into texts. In addition, these decoded predictions are transcribed into a file that will be stored in the indicated directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "adolescent-identifier",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def postprocess_text(preds, labels):\n",
    "    preds = [pred.strip() for pred in preds]\n",
    "    labels = [[label.strip()] for label in labels]\n",
    "    \n",
    "    return preds, labels\n",
    "    \n",
    "def compute_metrics_bleu(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    \n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "        \n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    decoded_preds, decoded_labels = postprocess_text(decoded_preds, decoded_labels)\n",
    "    \n",
    "    result = bleu_metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "    file = 'results-' + str(result['score']) + '.txt'\n",
    "    \n",
    "    result = {\"bleu\": result[\"score\"]}\n",
    "    \n",
    "    with open('experimentos/vigo_preentrenado/' + file, 'w') as f:\n",
    "        f.write('\\n'.join(decoded_preds))\n",
    "        \n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in preds]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    result = {k: round(v,4) for k, v in result.items()}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "aerial-ethics",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import numpy as np\n",
    "\n",
    "def compute_metrics_rouge(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    decoded_preds = tokenizer.batch_decode(predictions, skip_special_tokens=True)\n",
    "    # Replace -100 in the labels as we can't decode them.\n",
    "    labels = np.where(labels != -100, labels, tokenizer.pad_token_id)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "    \n",
    "    # Rouge expects a newline after each sentence\n",
    "    decoded_preds = [\"\\n\".join(nltk.sent_tokenize(pred.strip())) for pred in decoded_preds]\n",
    "    decoded_labels = [\"\\n\".join(nltk.sent_tokenize(label.strip())) for label in decoded_labels]\n",
    "    \n",
    "    result = rouge_metric.compute(predictions=decoded_preds, references=decoded_labels, use_stemmer=True)\n",
    "    # Extract a few results\n",
    "    result = {key: value.mid.fmeasure * 100 for key, value in result.items()}\n",
    "    \n",
    "    # Add mean generated length\n",
    "    prediction_lens = [np.count_nonzero(pred != tokenizer.pad_token_id) for pred in predictions]\n",
    "    result[\"gen_len\"] = np.mean(prediction_lens)\n",
    "    \n",
    "    return {k: round(v, 4) for k, v in result.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "recognized-briefs",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "    \n",
    "def compute_metrics_meteor(eval_preds):\n",
    "    preds, labels = eval_preds\n",
    "    \n",
    "    if isinstance(preds, tuple):\n",
    "        preds = preds[0]\n",
    "        \n",
    "    decoded_preds = tokenizer.batch_decode(preds, skip_special_tokens=True)\n",
    "    decoded_labels = tokenizer.batch_decode(labels, skip_special_tokens=True)\n",
    "        \n",
    "    result = meteor_metric.compute(predictions=decoded_preds, references=decoded_labels)\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amazing-treat",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "friendly-timing",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "associate-migration",
   "metadata": {},
   "source": [
    "## BLEU METRIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "lovely-newman",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp fp16 backend\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer_bleu = Seq2SeqTrainer(\n",
    "    modelo,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics_bleu,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "powered-spain",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 150\n",
      "  Batch size = 8\n",
      "/home/marina/anaconda3/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  /pytorch/aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.625372886657715, 'eval_bleu': 0.1771, 'eval_gen_len': 13.4133, 'eval_runtime': 4.6987, 'eval_samples_per_second': 31.924, 'eval_steps_per_second': 4.044}\n"
     ]
    }
   ],
   "source": [
    "bleu_predictions = trainer_bleu.predict(tokenized_dataset[\"test\"])\n",
    "print(bleu_predictions.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "working-slovenia",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "divided-science",
   "metadata": {},
   "source": [
    "## ROUGE METRIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "valued-practitioner",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp fp16 backend\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer_rouge = Seq2SeqTrainer(\n",
    "    modelo,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics_rouge,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "divided-stylus",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 150\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.625372886657715, 'eval_rouge1': 8.1796, 'eval_rouge2': 0.6847, 'eval_rougeL': 7.3327, 'eval_rougeLsum': 7.3565, 'eval_gen_len': 13.4133, 'eval_runtime': 4.8403, 'eval_samples_per_second': 30.99, 'eval_steps_per_second': 3.925}\n"
     ]
    }
   ],
   "source": [
    "rouge_predictions = trainer_rouge.predict(tokenized_dataset[\"test\"])\n",
    "print(rouge_predictions.metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ignored-attack",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vietnamese-anniversary",
   "metadata": {},
   "source": [
    "## METEOR METRIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "terminal-crown",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using amp fp16 backend\n"
     ]
    }
   ],
   "source": [
    "from transformers import Seq2SeqTrainer\n",
    "\n",
    "trainer_meteor = Seq2SeqTrainer(\n",
    "    modelo,\n",
    "    training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    data_collator=data_collator,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics_meteor,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "civic-landscape",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the test set  don't have a corresponding argument in `MarianMTModel.forward` and have been ignored: translation.\n",
      "***** Running Prediction *****\n",
      "  Num examples = 150\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='19' max='19' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [19/19 00:03]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 8.625372886657715, 'eval_meteor': 0.03173193607731098, 'eval_runtime': 5.598, 'eval_samples_per_second': 26.796, 'eval_steps_per_second': 3.394}\n"
     ]
    }
   ],
   "source": [
    "meteor_predictions = trainer_meteor.predict(tokenized_dataset[\"test\"])\n",
    "print(meteor_predictions.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "central-channels",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reverse-delay",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
